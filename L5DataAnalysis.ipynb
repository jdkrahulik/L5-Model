{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Relevant Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Request Data\n",
    "# ========================================\n",
    "### Men"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'https://iusf.indiana.edu/little500/results.html?raceType=Individual+Time+Trials&year=All&gender=M&teamName=&RiderName=&l500submit=Search#results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = requests.get(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mITT = pd.read_html(html.text)[0]\n",
    "mITT = mITT.astype(dtype={'Year': 'str'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSecs(time):\n",
    "    \"\"\"given a string in form mm:ss.ms, returns seconds as float\n",
    "    \n",
    "    str -> float\"\"\"\n",
    "    if type(time) != str:\n",
    "        return time\n",
    "    else:\n",
    "        try:\n",
    "            time = '00:' + time.strip()\n",
    "            secs = pd.to_timedelta(time).total_seconds()\n",
    "            return secs\n",
    "        except:\n",
    "            return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# convert 'Finish Time' col to seconds\n",
    "mITT['Finish Time'] = mITT['Finish Time'].apply(lambda x: getSecs(x))\n",
    "mITT = mITT.rename(columns={'Finish Time': 'secITT'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop corrupted rows\n",
    "mITT = mITT.drop(mITT[mITT['secITT'] == -1].index)\n",
    "mITT = mITT.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# add column for 'rank within each team'\n",
    "mITT['RankWithinTeam'] = mITT.groupby(by=['Team', 'Year'])['secITT'].transform(lambda x: np.arange(1, len(x) + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column for z-score by year\n",
    "zscore = zscore = lambda x: (x - x.mean()) / x.std()\n",
    "mITT['zscore'] = mITT.groupby('Year')['secITT'].transform(zscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Place</th>\n",
       "      <th>Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>secITT</th>\n",
       "      <th>RankWithinTeam</th>\n",
       "      <th>zscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>Joseph Krahulik</td>\n",
       "      <td>Sigma Alpha Epsilon</td>\n",
       "      <td>137.893</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.061474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>Xavier Martinez</td>\n",
       "      <td>Black Key Bulls</td>\n",
       "      <td>139.437</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.884708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>Ben Harris</td>\n",
       "      <td>Sigma Phi Epsilon</td>\n",
       "      <td>142.467</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.537817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018</td>\n",
       "      <td>M</td>\n",
       "      <td>4</td>\n",
       "      <td>Tom Settle</td>\n",
       "      <td>Sigma Phi Epsilon</td>\n",
       "      <td>142.503</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.533695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018</td>\n",
       "      <td>M</td>\n",
       "      <td>5</td>\n",
       "      <td>Matthew Thompson</td>\n",
       "      <td>3PH Cycling</td>\n",
       "      <td>142.630</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.519155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year Gender  Place              Name                 Team   secITT  \\\n",
       "0  2018      M      1   Joseph Krahulik  Sigma Alpha Epsilon  137.893   \n",
       "1  2018      M      2   Xavier Martinez      Black Key Bulls  139.437   \n",
       "2  2018      M      3        Ben Harris    Sigma Phi Epsilon  142.467   \n",
       "3  2018      M      4        Tom Settle    Sigma Phi Epsilon  142.503   \n",
       "4  2018      M      5  Matthew Thompson          3PH Cycling  142.630   \n",
       "\n",
       "   RankWithinTeam    zscore  \n",
       "0             1.0 -2.061474  \n",
       "1             1.0 -1.884708  \n",
       "2             1.0 -1.537817  \n",
       "3             2.0 -1.533695  \n",
       "4             1.0 -1.519155  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mITT.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================\n",
    "\n",
    "### Women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = r'https://iusf.indiana.edu/little500/results.html?raceType=Individual+Time+Trials&year=All&gender=F&teamName=&RiderName=&l500submit=Search#results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fhtml = requests.get(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fITT = pd.read_html(fhtml.text)[0]\n",
    "fITT = fITT.astype(dtype={'Year': 'str'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# convert 'Finish Time' col to seconds\n",
    "fITT['Finish Time'] = fITT['Finish Time'].apply(lambda x: getSecs(x))\n",
    "fITT = fITT.rename(columns={'Finish Time': 'secITT'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop corrupted rows\n",
    "fITT = fITT.drop(fITT[fITT['secITT'] == -1].index)\n",
    "fITT = fITT.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# add column for 'rank within each team'\n",
    "fITT['RankWithinTeam'] = fITT.groupby(by=['Team', 'Year'])['secITT'].transform(lambda x: np.arange(1, len(x) + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column for z-score by year\n",
    "zscore = zscore = lambda x: (x - x.mean()) / x.std()\n",
    "fITT['zscore'] = fITT.groupby('Year')['secITT'].transform(zscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Place</th>\n",
       "      <th>Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>secITT</th>\n",
       "      <th>RankWithinTeam</th>\n",
       "      <th>zscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>Brooke Hannon</td>\n",
       "      <td>Melanzana</td>\n",
       "      <td>153.083</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.824415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "      <td>Rachel Brown</td>\n",
       "      <td>Kappa Alpha Theta</td>\n",
       "      <td>153.637</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.788392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>F</td>\n",
       "      <td>3</td>\n",
       "      <td>Caitlin Kamplain</td>\n",
       "      <td>Theta Phi Alpha</td>\n",
       "      <td>157.197</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.556911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018</td>\n",
       "      <td>F</td>\n",
       "      <td>4</td>\n",
       "      <td>Hanna Coppens</td>\n",
       "      <td>Delta Gamma</td>\n",
       "      <td>157.235</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.554440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>Audrey Morlan</td>\n",
       "      <td>Delta Gamma</td>\n",
       "      <td>159.583</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.401767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year Gender  Place              Name               Team   secITT  \\\n",
       "0  2018      F      1     Brooke Hannon          Melanzana  153.083   \n",
       "1  2018      F      2      Rachel Brown  Kappa Alpha Theta  153.637   \n",
       "2  2018      F      3  Caitlin Kamplain    Theta Phi Alpha  157.197   \n",
       "3  2018      F      4     Hanna Coppens        Delta Gamma  157.235   \n",
       "4  2018      F      5     Audrey Morlan        Delta Gamma  159.583   \n",
       "\n",
       "   RankWithinTeam    zscore  \n",
       "0             1.0 -1.824415  \n",
       "1             1.0 -1.788392  \n",
       "2             1.0 -1.556911  \n",
       "3             1.0 -1.554440  \n",
       "4             2.0 -1.401767  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fITT.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================\n",
    "\n",
    "### Men Team Pursuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mppath = r'https://iusf.indiana.edu/little500/results.html?raceType=Team+Pursuit&year=All&gender=M&teamName=&l500submit=Search#results'\n",
    "mphtml = requests.get(mppath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mTP = pd.read_html(mphtml.text)[0]\n",
    "mTP = mTP.drop(labels='Finals Time', axis=1)\n",
    "mTP = mTP.astype(dtype={'Year': 'str'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# convert 'Finish Time' col to seconds\n",
    "mTP['Finish Time'] = mTP['Finish Time'].apply(lambda x: getSecs(x))\n",
    "mTP = mTP.rename(columns={'Finish Time': 'secTP'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up trailing numbers from team names and drop 2nd teams\n",
    "\n",
    "def removeNum(team):\n",
    "    \"\"\"removes trailing number '1' from teams that enter two teams\n",
    "    \n",
    "    str -> str\"\"\"\n",
    "    if team[-1] == '1':\n",
    "        return team[:-2]\n",
    "    else:\n",
    "        return team\n",
    "    \n",
    "mTP['Team'] = mTP['Team'].transform(lambda x: removeNum(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add z-score to each row based on entries from the same year\n",
    "mTP['zscore'] = mTP.groupby('Year')['secTP'].transform(lambda x: zscore(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Place</th>\n",
       "      <th>Team</th>\n",
       "      <th>secTP</th>\n",
       "      <th>zscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>Sigma Phi Epsilon</td>\n",
       "      <td>550.40</td>\n",
       "      <td>-0.910551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>Black Key Bulls</td>\n",
       "      <td>556.20</td>\n",
       "      <td>-0.827738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>Sigma Alpha Epsilon</td>\n",
       "      <td>564.11</td>\n",
       "      <td>-0.714798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018</td>\n",
       "      <td>M</td>\n",
       "      <td>4</td>\n",
       "      <td>Bears</td>\n",
       "      <td>571.87</td>\n",
       "      <td>-0.604001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018</td>\n",
       "      <td>M</td>\n",
       "      <td>5</td>\n",
       "      <td>Beta Theta Pi</td>\n",
       "      <td>573.51</td>\n",
       "      <td>-0.580585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year Gender  Place                 Team   secTP    zscore\n",
       "0  2018      M      1    Sigma Phi Epsilon  550.40 -0.910551\n",
       "1  2018      M      2      Black Key Bulls  556.20 -0.827738\n",
       "2  2018      M      3  Sigma Alpha Epsilon  564.11 -0.714798\n",
       "3  2018      M      4                Bears  571.87 -0.604001\n",
       "4  2018      M      5        Beta Theta Pi  573.51 -0.580585"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mTP.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================\n",
    "\n",
    "### Women Team Pursuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "fppath = r'https://iusf.indiana.edu/little500/results.html?raceType=Team+Pursuit&year=All&gender=F&teamName=&l500submit=Search#results'\n",
    "fphtml = requests.get(fppath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "fTP = pd.read_html(fphtml.text)[0]\n",
    "fTP = fTP.drop(labels='Finals Time', axis=1)\n",
    "fTP = fTP.astype(dtype={'Year': 'str'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# convert 'Finish Time' col to seconds\n",
    "fTP['Finish Time'] = fTP['Finish Time'].apply(lambda x: getSecs(x))\n",
    "fTP = fTP.rename(columns={'Finish Time': 'secTP'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "fTP['Team'] = fTP['Team'].transform(lambda x: removeNum(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add z-score to each row based on entries from the same year\n",
    "fTP['zscore'] = fTP.groupby('Year')['secTP'].transform(lambda x: zscore(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Place</th>\n",
       "      <th>Team</th>\n",
       "      <th>secTP</th>\n",
       "      <th>zscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>Melanzana</td>\n",
       "      <td>500.05</td>\n",
       "      <td>-1.655863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "      <td>Kappa Alpha Theta</td>\n",
       "      <td>511.28</td>\n",
       "      <td>-1.376660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>F</td>\n",
       "      <td>3</td>\n",
       "      <td>SKI</td>\n",
       "      <td>523.62</td>\n",
       "      <td>-1.069859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018</td>\n",
       "      <td>F</td>\n",
       "      <td>4</td>\n",
       "      <td>Teter</td>\n",
       "      <td>523.65</td>\n",
       "      <td>-1.069113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>Alpha Chi Omega</td>\n",
       "      <td>524.13</td>\n",
       "      <td>-1.057179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year Gender  Place               Team   secTP    zscore\n",
       "0  2018      F      1          Melanzana  500.05 -1.655863\n",
       "1  2018      F      2  Kappa Alpha Theta  511.28 -1.376660\n",
       "2  2018      F      3                SKI  523.62 -1.069859\n",
       "3  2018      F      4              Teter  523.65 -1.069113\n",
       "4  2018      F      5    Alpha Chi Omega  524.13 -1.057179"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fTP.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================\n",
    "\n",
    "### Men Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrpath = r'https://iusf.indiana.edu/little500/results.html?raceType=Little+500+Race&year=All&gender=M&teamName=&l500submit=Search#results'\n",
    "mrhtml = requests.get(mrpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "mR = pd.read_html(mrhtml.text)[0]\n",
    "mR = mR.astype(dtype={'Year': 'int64'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.555555555555555"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mR[(mR['Laps']>=197) & (mR['Year'] >2009)].groupby('Year')['Laps'].count().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================\n",
    "\n",
    "### Women Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrpath = r'https://iusf.indiana.edu/little500/results.html?raceType=Little+500+Race&year=All&gender=F&teamName=&l500submit=Search#results'\n",
    "wrhtml = requests.get(wrpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "wR = pd.read_html(wrhtml.text)[0]\n",
    "wR = wR.astype(dtype={'Year': 'int64'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.88888888888889"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wR[(wR['Laps']>=97) & (wR['Year'] >2009)].groupby('Year')['Laps'].count().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================\n",
    "\n",
    "### Men Quals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "mqualsPath = r'https://iusf.indiana.edu/little500/results.html?raceType=Qualifications&year=All&gender=M&teamName=&l500submit=Search#results'\n",
    "mqualtshtml = requests.get(mqualsPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "mQ = pd.read_html(mqualtshtml.text)[0]\n",
    "mQ = mQ.astype(dtype={'Year': 'int64'})\n",
    "mQ = mQ.rename(columns={'Finish Time': 'secQuals'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "mQ['secQuals'] = mQ['secQuals'].apply(lambda x: getSecs(x))\n",
    "mQ['zscore'] = mQ.groupby('Year')['secQuals'].apply(lambda x: zscore(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Place</th>\n",
       "      <th>Team</th>\n",
       "      <th>secQuals</th>\n",
       "      <th>zscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>Cutters</td>\n",
       "      <td>154.973</td>\n",
       "      <td>-1.741349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>Kappa Sigma</td>\n",
       "      <td>155.052</td>\n",
       "      <td>-1.731198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>Sigma Alpha Epsilon</td>\n",
       "      <td>157.798</td>\n",
       "      <td>-1.378366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018</td>\n",
       "      <td>M</td>\n",
       "      <td>4</td>\n",
       "      <td>Sigma Phi Epsilon</td>\n",
       "      <td>159.377</td>\n",
       "      <td>-1.175481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018</td>\n",
       "      <td>M</td>\n",
       "      <td>5</td>\n",
       "      <td>Pi Lambda Phi</td>\n",
       "      <td>159.491</td>\n",
       "      <td>-1.160833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year Gender  Place                 Team  secQuals    zscore\n",
       "0  2018      M      1              Cutters   154.973 -1.741349\n",
       "1  2018      M      2          Kappa Sigma   155.052 -1.731198\n",
       "2  2018      M      3  Sigma Alpha Epsilon   157.798 -1.378366\n",
       "3  2018      M      4    Sigma Phi Epsilon   159.377 -1.175481\n",
       "4  2018      M      5        Pi Lambda Phi   159.491 -1.160833"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mQ.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================\n",
    "\n",
    "### Women Quals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "fqualsPath = r'https://iusf.indiana.edu/little500/results.html?raceType=Qualifications&year=All&gender=F&teamName=&l500submit=Search#results'\n",
    "fqualtshtml = requests.get(fqualsPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "fQ = pd.read_html(fqualtshtml.text)[0]\n",
    "fQ = fQ.astype(dtype={'Year': 'int64'})\n",
    "fQ = fQ.rename(columns={'Finish Time': 'secQuals'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "fQ['secQuals'] = fQ['secQuals'].apply(lambda x: getSecs(x))\n",
    "fQ['zscore'] = fQ.groupby('Year')['secQuals'].apply(lambda x: zscore(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Place</th>\n",
       "      <th>Team</th>\n",
       "      <th>secQuals</th>\n",
       "      <th>zscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>Delta Gamma</td>\n",
       "      <td>171.359</td>\n",
       "      <td>-1.648757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "      <td>Kappa Alpha Theta</td>\n",
       "      <td>177.661</td>\n",
       "      <td>-1.248071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>F</td>\n",
       "      <td>3</td>\n",
       "      <td>Alpha Gamma Delta</td>\n",
       "      <td>178.694</td>\n",
       "      <td>-1.182392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018</td>\n",
       "      <td>F</td>\n",
       "      <td>4</td>\n",
       "      <td>Alpha Chi Omega</td>\n",
       "      <td>180.349</td>\n",
       "      <td>-1.077166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>Teter</td>\n",
       "      <td>180.452</td>\n",
       "      <td>-1.070617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year Gender  Place               Team  secQuals    zscore\n",
       "0  2018      F      1        Delta Gamma   171.359 -1.648757\n",
       "1  2018      F      2  Kappa Alpha Theta   177.661 -1.248071\n",
       "2  2018      F      3  Alpha Gamma Delta   178.694 -1.182392\n",
       "3  2018      F      4    Alpha Chi Omega   180.349 -1.077166\n",
       "4  2018      F      5              Teter   180.452 -1.070617"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fQ.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging the DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# DataFrame will contain 'aITT', 'bITT', 'cITT', 'TP', 'Result'\n",
    "\n",
    "# mR only select years after 2000\n",
    "# Create TeamIndex as primary key\n",
    "# Create TeamIndex in mTP and mITT as foreign key\n",
    "\n",
    "wrk_Race = mR.iloc[:, [0,3,2]]\n",
    "wrk_Race = wrk_Race[wrk_Race['Year']>=2000]\n",
    "wrk_Race['TeamID'] = np.arange(0,len(wrk_Race),1)\n",
    "wrk_Race = wrk_Race[['TeamID', 'Year', 'Team', 'Place']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID          int64\n",
       "Year       object\n",
       "Team       object\n",
       "zscore    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrk_ITT.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TeamID     int64\n",
       "Year       int64\n",
       "Team      object\n",
       "Place      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrk_Race.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jdkrahulik/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "mITT.head()\n",
    "wrk_ITT = mITT.iloc[:, [0,4,7]]\n",
    "wrk_ITT['ID'] = np.arange(0, len(wrk_ITT), 1)\n",
    "wrk_ITT = wrk_ITT.iloc[:, [3,0,1,2]]\n",
    "wrk_ITT = wrk_ITT.astype(dtype={'Year': 'int64'})\n",
    "\n",
    "wrk_ITT = wrk_ITT.merge(right=wrk_Race[['TeamID','Year', 'Team']],\n",
    "              on=['Team', 'Year'], how='left').dropna().astype(dtype={'TeamID': 'int64'})\n",
    "wrk_ITT = wrk_ITT.iloc[:, [0,4,1,2,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "mTP['ID'] = np.arange(0,len(mTP), 1)\n",
    "wrk_TP = mTP.iloc[:, [6,0,3,5]]\n",
    "wrk_TP = wrk_TP.astype(dtype={'Year': 'int64'})\n",
    "wrk_TP = wrk_TP.merge(right=wrk_Race.iloc[:, [0,1,2]], \n",
    "                      on=['Year', 'Team'], how='left').dropna().astype(dtype={'TeamID': 'int64'})\n",
    "wrk_TP = wrk_TP.iloc[:, [0,4,1,2,3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrames are all stripped down to include only relevant information.  Now need to merge team pursuit data into race frame as well as merge ITT data into race frame.  I will do team pursuit first since it is an easier composition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging Team Pursuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TeamID</th>\n",
       "      <th>Year</th>\n",
       "      <th>Team</th>\n",
       "      <th>zscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2018</td>\n",
       "      <td>Sigma Phi Epsilon</td>\n",
       "      <td>-0.910551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2018</td>\n",
       "      <td>Black Key Bulls</td>\n",
       "      <td>-0.827738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2018</td>\n",
       "      <td>Sigma Alpha Epsilon</td>\n",
       "      <td>-0.714798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2018</td>\n",
       "      <td>Bears</td>\n",
       "      <td>-0.604001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2018</td>\n",
       "      <td>Beta Theta Pi</td>\n",
       "      <td>-0.580585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  TeamID  Year                 Team    zscore\n",
       "0   0       3  2018    Sigma Phi Epsilon -0.910551\n",
       "1   1       2  2018      Black Key Bulls -0.827738\n",
       "2   2       5  2018  Sigma Alpha Epsilon -0.714798\n",
       "3   3       6  2018                Bears -0.604001\n",
       "4   4       7  2018        Beta Theta Pi -0.580585"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrk_TP.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrk_table = wrk_Race.merge(right=wrk_TP.iloc[:,[1,4]], on='TeamID', how='left')\n",
    "wrk_table = wrk_table.rename(columns={'zscore': 'TP'})\n",
    "# Success"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging ITT results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by grouping ITT results by TeamID\n",
    "grouped_ITT = wrk_ITT.groupby('TeamID')\n",
    "grouped_ITT = grouped_ITT['zscore'].apply(lambda x: x.reset_index(drop=True)).unstack().reset_index()\n",
    "\n",
    "wrk_table = wrk_table.merge(right=grouped_ITT.iloc[:, [0,1,2,3,4]], on='TeamID', how='left')\n",
    "wrk_table = wrk_table.rename(columns={0: 'aITT', 1: 'bITT', 2: 'cITT', 3: 'dITT'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TeamID</th>\n",
       "      <th>Year</th>\n",
       "      <th>Team</th>\n",
       "      <th>Place</th>\n",
       "      <th>TP</th>\n",
       "      <th>aITT</th>\n",
       "      <th>bITT</th>\n",
       "      <th>cITT</th>\n",
       "      <th>dITT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>Cutters</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.431803</td>\n",
       "      <td>-0.897155</td>\n",
       "      <td>-0.892919</td>\n",
       "      <td>0.568720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>Gray Goat</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.391686</td>\n",
       "      <td>-1.477139</td>\n",
       "      <td>-0.931042</td>\n",
       "      <td>-0.905512</td>\n",
       "      <td>-0.833043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2018</td>\n",
       "      <td>Black Key Bulls</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.827738</td>\n",
       "      <td>-1.884708</td>\n",
       "      <td>-1.358875</td>\n",
       "      <td>-1.212677</td>\n",
       "      <td>-0.790683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2018</td>\n",
       "      <td>Sigma Phi Epsilon</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.910551</td>\n",
       "      <td>-1.537817</td>\n",
       "      <td>-1.533695</td>\n",
       "      <td>-1.308845</td>\n",
       "      <td>0.103107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2018</td>\n",
       "      <td>Jetblach</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.103572</td>\n",
       "      <td>-0.809001</td>\n",
       "      <td>-0.704017</td>\n",
       "      <td>-0.607849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TeamID  Year               Team  Place        TP      aITT      bITT  \\\n",
       "0       0  2018            Cutters      1       NaN -1.431803 -0.897155   \n",
       "1       1  2018          Gray Goat      2 -0.391686 -1.477139 -0.931042   \n",
       "2       2  2018    Black Key Bulls      3 -0.827738 -1.884708 -1.358875   \n",
       "3       3  2018  Sigma Phi Epsilon      4 -0.910551 -1.537817 -1.533695   \n",
       "4       4  2018           Jetblach      5       NaN -1.103572 -0.809001   \n",
       "\n",
       "       cITT      dITT  \n",
       "0 -0.892919  0.568720  \n",
       "1 -0.905512 -0.833043  \n",
       "2 -1.212677 -0.790683  \n",
       "3 -1.308845  0.103107  \n",
       "4 -0.704017 -0.607849  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrk_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into X, y\n",
    "X = wrk_table.iloc[:, 4:9].values\n",
    "y = wrk_table.iloc[:, 3].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup numeric transformer\n",
    "# This will usually entail handling missing variables then scaling\n",
    "num_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value=0))])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', num_transformer, [0,1,2,3,4])])\n",
    "\n",
    "X = preprocessor.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test set\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Convert y into binary column where 1=win, 0=else\n",
    "y_win_train = (y_train == 1).astype('int64')\n",
    "y_win_test = (y_test == 1).astype('int64')\n",
    "\n",
    "log_regressor = LogisticRegression(solver='lbfgs')\n",
    "log_regressor.fit(X_train, y_win_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_2 = np.append(np.ones(shape=(len(X_train), 1)), X_train, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.088921\n",
      "         Iterations 10\n"
     ]
    }
   ],
   "source": [
    "logit_reg = sm.Logit(y_win_train, X_train_2[:, [0,1,3,4,5]]).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>y</td>        <th>  No. Observations:  </th>  <td>   501</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   496</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     4</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Sun, 10 Mar 2019</td> <th>  Pseudo R-squ.:     </th>  <td>0.4255</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>19:26:18</td>     <th>  Log-Likelihood:    </th> <td> -44.550</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -77.545</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>1.591e-13</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   -6.9813</td> <td>    1.236</td> <td>   -5.648</td> <td> 0.000</td> <td>   -9.404</td> <td>   -4.559</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -0.5412</td> <td>    0.593</td> <td>   -0.912</td> <td> 0.362</td> <td>   -1.704</td> <td>    0.621</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -3.2678</td> <td>    1.230</td> <td>   -2.657</td> <td> 0.008</td> <td>   -5.679</td> <td>   -0.857</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.1381</td> <td>    1.192</td> <td>    0.116</td> <td> 0.908</td> <td>   -2.198</td> <td>    2.474</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -0.5972</td> <td>    1.046</td> <td>   -0.571</td> <td> 0.568</td> <td>   -2.648</td> <td>    1.454</td>\n",
       "</tr>\n",
       "</table><br/><br/>Possibly complete quasi-separation: A fraction 0.17 of observations can be<br/>perfectly predicted. This might indicate that there is complete<br/>quasi-separation. In this case some parameters will not be identified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                  501\n",
       "Model:                          Logit   Df Residuals:                      496\n",
       "Method:                           MLE   Df Model:                            4\n",
       "Date:                Sun, 10 Mar 2019   Pseudo R-squ.:                  0.4255\n",
       "Time:                        19:26:18   Log-Likelihood:                -44.550\n",
       "converged:                       True   LL-Null:                       -77.545\n",
       "                                        LLR p-value:                 1.591e-13\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         -6.9813      1.236     -5.648      0.000      -9.404      -4.559\n",
       "x1            -0.5412      0.593     -0.912      0.362      -1.704       0.621\n",
       "x2            -3.2678      1.230     -2.657      0.008      -5.679      -0.857\n",
       "x3             0.1381      1.192      0.116      0.908      -2.198       2.474\n",
       "x4            -0.5972      1.046     -0.571      0.568      -2.648       1.454\n",
       "==============================================================================\n",
       "\n",
       "Possibly complete quasi-separation: A fraction 0.17 of observations can be\n",
       "perfectly predicted. This might indicate that there is complete\n",
       "quasi-separation. In this case some parameters will not be identified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_reg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9700598802395209\n",
      "Test Accuracy: 0.9920634920634921\n"
     ]
    }
   ],
   "source": [
    "print('Training Accuracy:', accuracy_score(y_win_train, log_regressor.predict(X_train)))\n",
    "print('Test Accuracy:', accuracy_score(y_win_test, log_regressor.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tremendous accuracy achieved by this model is a bit of a red herring. There are very few winners in the sample (1 per year, or 1/33). The model therefore achieves pretty high accuracy simply assigning 0 outcome to every case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.5833333333333334\n",
      "Test Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "print('Training Accuracy:', balanced_accuracy_score(y_win_train, log_regressor.predict(X_train)))\n",
    "print('Test Accuracy:', balanced_accuracy_score(y_win_test, log_regressor.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.88618761, 0.11381239],\n",
       "       [0.89274303, 0.10725697],\n",
       "       [0.65150493, 0.34849507],\n",
       "       [0.89230586, 0.10769414],\n",
       "       [0.88273647, 0.11726353],\n",
       "       [0.89737216, 0.10262784],\n",
       "       [0.79951802, 0.20048198],\n",
       "       [0.73126076, 0.26873924],\n",
       "       [0.87931223, 0.12068777],\n",
       "       [0.8678081 , 0.1321919 ],\n",
       "       [0.83633711, 0.16366289],\n",
       "       [0.54497899, 0.45502101]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_regressor.predict_proba(X_test)[log_regressor.predict_proba(X_test)[:, 1] > .10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the probabilities assigned to to the predictions shows just how heavily skewed towards zero this model is. Within the training set only two teams achieved a winning probability great enough to be assigned a 1 outcome. This may not necessarily be a shortcoming of the model. Very rarely are there teams that have realistically more than 1/5 odds of winning. If that wasn't reflected here then that would indicate bigger problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Top-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.457195\n",
      "         Iterations 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>y</td>        <th>  No. Observations:  </th>  <td>   501</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   496</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     4</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Sun, 10 Mar 2019</td> <th>  Pseudo R-squ.:     </th> <td>-0.08292</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>19:41:36</td>     <th>  Log-Likelihood:    </th> <td> -229.05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -211.52</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th>  <td> 1.000</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>     <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th> <td>   -0.9708</td> <td>    0.250</td> <td>   -3.889</td> <td> 0.000</td> <td>   -1.460</td> <td>   -0.482</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th> <td>    1.8409</td> <td>    0.280</td> <td>    6.581</td> <td> 0.000</td> <td>    1.293</td> <td>    2.389</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th> <td>   -0.8441</td> <td>    0.363</td> <td>   -2.324</td> <td> 0.020</td> <td>   -1.556</td> <td>   -0.132</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th> <td>   -0.8559</td> <td>    0.314</td> <td>   -2.724</td> <td> 0.006</td> <td>   -1.472</td> <td>   -0.240</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th> <td>   -1.1368</td> <td>    0.293</td> <td>   -3.886</td> <td> 0.000</td> <td>   -1.710</td> <td>   -0.563</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                  501\n",
       "Model:                          Logit   Df Residuals:                      496\n",
       "Method:                           MLE   Df Model:                            4\n",
       "Date:                Sun, 10 Mar 2019   Pseudo R-squ.:                -0.08292\n",
       "Time:                        19:41:36   Log-Likelihood:                -229.05\n",
       "converged:                       True   LL-Null:                       -211.52\n",
       "                                        LLR p-value:                     1.000\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1            -0.9708      0.250     -3.889      0.000      -1.460      -0.482\n",
       "x2             1.8409      0.280      6.581      0.000       1.293       2.389\n",
       "x3            -0.8441      0.363     -2.324      0.020      -1.556      -0.132\n",
       "x4            -0.8559      0.314     -2.724      0.006      -1.472      -0.240\n",
       "x5            -1.1368      0.293     -3.886      0.000      -1.710      -0.563\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_5 = (y_train <= 5).astype('int64')\n",
    "y_test_5 = (y_test <= 5).astype('int64')\n",
    "\n",
    "log_regressor_5 = sm.Logit(y_train_5, X_train).fit()\n",
    "log_regressor_5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_regressor_5 = LogisticRegression(solver='lbfgs')\n",
    "log_regressor_5.fit(X_train, y_train_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.8862275449101796\n",
      "Test Accuracy: 0.873015873015873\n"
     ]
    }
   ],
   "source": [
    "print('Training Accuracy:', accuracy_score(y_train_5, log_regressor_5.predict(X_train)))\n",
    "print('Test Accuracy:', accuracy_score(y_test_5, log_regressor_5.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.7298591549295774\n",
      "Test Accuracy: 0.7216981132075472\n"
     ]
    }
   ],
   "source": [
    "print('Training Accuracy:', balanced_accuracy_score(y_train_5, log_regressor_5.predict(X_train)))\n",
    "print('Test Accuracy:', balanced_accuracy_score(y_test_5, log_regressor_5.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a logistic classification model for the top 5 seems to yield pretty reliable results. Accuracy scores hovering in the upper 80%s for both test and training data, and low-70% for balanced accuracy metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import brier_score_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07874906334552223"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brier_score_loss(y_test_5, log_regressor_5.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that this model is pretty good represented by the brier loss score of 0.07."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy (Winner): 1.0\n",
      "Test Accuracy (Winner): 0.9920634920634921 \n",
      "\n",
      "Training Balanced Accuracy (Winner): 1.0\n",
      "Test Balanced Accuracy (Winner): 0.5 \n",
      "\n",
      "Brier Score (Winner): 0.012486155202821871\n"
     ]
    }
   ],
   "source": [
    "RFR_classifier = RandomForestClassifier(n_estimators=300)\n",
    "RFR_classifier.fit(X_train, y_win_train)\n",
    "\n",
    "print('Training Accuracy (Winner):', accuracy_score(y_win_train, RFR_classifier.predict(X_train)))\n",
    "print('Test Accuracy (Winner):', accuracy_score(y_win_test, RFR_classifier.predict(X_test)), '\\n')\n",
    "print('Training Balanced Accuracy (Winner):', balanced_accuracy_score(y_win_train, RFR_classifier.predict(X_train)))\n",
    "print('Test Balanced Accuracy (Winner):', balanced_accuracy_score(y_win_test, RFR_classifier.predict(X_test)), '\\n')\n",
    "\n",
    "print('Brier Score (Winner):', brier_score_loss(y_win_test, RFR_classifier.predict_proba(X_test)[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above model has a lot of promise. Still, the P(win) is adequatly small that there should be room for skepticism. Next, I'll make a similar Random Forest Classifer for Top-3 finishers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy (Top-3): 0.998003992015968\n",
      "Test Accuracy (Top-3): 0.8968253968253969 \n",
      "\n",
      "Training Balanced Accuracy (Top-3): 0.9891304347826086\n",
      "Test Balanced Accuracy (Top-3): 0.5324110671936759 \n",
      "\n",
      "Brier Score (Top-3): 0.06600264892437474\n"
     ]
    }
   ],
   "source": [
    "y_train_3 = (y_train <= 3).astype('int64')\n",
    "y_test_3 = (y_test <= 3).astype('int64')\n",
    "\n",
    "RFR_classifier.fit(X_train, y_train_3)\n",
    "\n",
    "print('Training Accuracy (Top-3):', accuracy_score(y_train_3, RFR_classifier.predict(X_train)))\n",
    "print('Test Accuracy (Top-3):', accuracy_score(y_test_3, RFR_classifier.predict(X_test)), '\\n')\n",
    "print('Training Balanced Accuracy (Top-3):', balanced_accuracy_score(y_train_3, RFR_classifier.predict(X_train)))\n",
    "print('Test Balanced Accuracy (Top-3):', balanced_accuracy_score(y_test_3, RFR_classifier.predict(X_test)), '\\n')\n",
    "\n",
    "print('Brier Score (Top-3):', brier_score_loss(y_test_3, RFR_classifier.predict_proba(X_test)[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More promising Results here! Overall score is down slightly in the test set, but the model is more generally applicable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=None,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFR_regressor = RandomForestRegressor(n_estimators=300)\n",
    "RFR_regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = RFR_regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 5.348691730695017\n"
     ]
    }
   ],
   "source": [
    "RMSE = (mean_squared_error(y_test, y_pred))**(1/2)\n",
    "\n",
    "print('RMSE:', RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.scatter(log_regressor.predict_proba(X_test)[:, 1], y_win_test, color='red')\n",
    "plt.title('Test Parameters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "RFR_regressor = RandomForestRegressor(n_estimators=100)\n",
    "RFR_regressor.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFR_classifier = RandomForestClassifier(n_estimators=100)\n",
    "RFR_classifier.fit(X_train, y_train_5)\n",
    "\n",
    "a_train = (y_train <= 3).astype('int64')\n",
    "a_test = (y_test <= 3).astype('int64')\n",
    "\n",
    "RFR_classifier.fit(X_train, a_train)\n",
    "RFR_classifier.score(X_test, a_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "met.roc_auc_score(a_test, RFR_classifier.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_win_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "RFR_regressor.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export to MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy\n",
    "import pymysql\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = sqlalchemy.create_engine('mysql+pymysql://root:Purpsqlle01@localhost:3306/exercises')\n",
    "# engine = sqlalchemy.create_engine('mysql+pymysql://user:password@server:port/schema')\n",
    "\n",
    "engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mITT.to_sql('ITT', con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mR.to_sql('Race', con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mTP.to_sql('TP', con=engine)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
